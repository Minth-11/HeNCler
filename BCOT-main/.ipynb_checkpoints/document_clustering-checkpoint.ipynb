{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATawChj-KEB5"
   },
   "source": [
    " # EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IhXzrKmR_oul",
    "outputId": "5795ab00-0398-4aab-f725-f3af036eec7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/BCOT'\n",
      "/volume1/scratch/zopdebee/GitHub/HeNCler/BCOT-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-1X\n",
      "acc: 51.4±1.7 & nmi: 15.8±1.2 & ari: 12.3±1.3\n",
      "time: 6.46±2.07\n",
      "db-index: 7.3±0.2\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-19717X\n",
      "acc: 51.2±0.2 & nmi: 15.3±0.1 & ari: 11.8±0.0\n",
      "time: 3.83±1.19\n",
      "db-index: 7.1±0.0\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-500X\n",
      "acc: 50.1±0.9 & nmi: 14.6±0.2 & ari: 11.2±0.3\n",
      "time: 3.38±0.03\n",
      "db-index: 7.1±0.0\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-3X\n",
      "acc: 45.8±1.9 & nmi: 11.3±0.3 & ari: 8.4±0.6\n",
      "time: 3.3±0.21\n",
      "db-index: 7.5±0.4\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on acm\n",
      "L(X)=-1X\n",
      "acc: 76.3±2.1 & nmi: 37.7±2.9 & ari: 42.5±3.7\n",
      "time: 0.44±0.01\n",
      "db-index: 9.7±0.0\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on acm\n",
      "L(X)=-3025X\n",
      "acc: 77.0±1.1 & nmi: 38.5±1.7 & ari: 43.8±2.1\n",
      "time: 0.44±0.05\n",
      "db-index: 9.8±0.0\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on acm\n",
      "L(X)=-1870X\n",
      "acc: 76.5±1.0 & nmi: 37.5±1.6 & ari: 42.8±1.9\n",
      "time: 0.6±0.3\n",
      "db-index: 9.8±0.1\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on acm\n",
      "L(X)=-3X\n",
      "acc: 76.5±0.8 & nmi: 37.8±1.1 & ari: 42.9±1.5\n",
      "time: 0.47±0.06\n",
      "db-index: 9.8±0.0\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dblp.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:39\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/dblp.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#for dataset in ['wiki', 'pubmed', 'ng20']:\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m#for dataset in ['wiki', 'pubmed', 'acm', 'dblp', 'ohscal', 'ng20']:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mpubmed\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33macm\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdblp\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m   features, labels, n_classes = \u001b[43mread_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m   n, d = features.shape\n\u001b[32m     26\u001b[39m   k = n_classes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/GitHub/HeNCler/BCOT-main/bcot/utils.py:40\u001b[39m, in \u001b[36mread_dataset\u001b[39m\u001b[34m(dataset, sparse)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_dataset\u001b[39m(dataset, sparse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     data = \u001b[43msio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.mat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     features = data[\u001b[33m'\u001b[39m\u001b[33mfea\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(features):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:233\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03mLoad MATLAB file.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m \u001b[33;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m variable_names = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mvariable_names\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    234\u001b[39m     MR, _ = mat_reader_factory(f, **kwargs)\n\u001b[32m    235\u001b[39m     matfile_dict = MR.get_variables(variable_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:17\u001b[39m, in \u001b[36m_open_file_context\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_context\u001b[39m(file_like, appendmat, mode=\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     f, opened = \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:45\u001b[39m, in \u001b[36m_open_file\u001b[39m\u001b[34m(file_like, appendmat, mode)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like.endswith(\u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     44\u001b[39m         file_like += \u001b[33m'\u001b[39m\u001b[33m.mat\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mReader needs file name or open file-like object\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     49\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/dblp.mat'"
     ]
    }
   ],
   "source": [
    "%cd /content/BCOT\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from bcot.utils import read_dataset\n",
    "from bcot.bcot import BCOT\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi \n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from bcot.metrics import clustering_accuracy\n",
    "import numpy as np\n",
    "from time import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "n_runs = 20\n",
    "plot_block_structure = False\n",
    "\n",
    "#for dataset in ['wiki', 'pubmed', 'ng20']:\n",
    "#for dataset in ['wiki', 'pubmed', 'acm', 'dblp', 'ohscal', 'ng20']:\n",
    "for dataset in ['pubmed','acm']:\n",
    "  features, labels, n_classes = read_dataset(dataset, sparse=True)\n",
    "  n, d = features.shape\n",
    "  k = n_classes\n",
    "\n",
    "  for scaler in [1, n, d, k]:    \n",
    "\n",
    "    metrics = {}\n",
    "    metrics['time'] = []\n",
    "    metrics['acc'] = []\n",
    "    metrics['nmi'] = []\n",
    "    metrics['ari'] = []\n",
    "    metrics['db'] = []\n",
    "    metrics['avg_n_clust'] = []\n",
    "    \n",
    "\n",
    "    for _ in tqdm(range(n_runs)):\n",
    "      t0 = time()\n",
    "      M = -features * scaler\n",
    "      \n",
    "      Z_p, W_p = BCOT(M, n_classes, algorithm='emd', reg=1, n_iter=100)\n",
    "\n",
    "      Z = Z_p.argmax(-1)\n",
    "      W = W_p.argmax(-1)\n",
    "\n",
    "      metrics['time'].append(time()-t0)\n",
    "      metrics['acc'].append(clustering_accuracy(labels, Z)*100)\n",
    "      metrics['nmi'].append(nmi(labels, Z)*100)\n",
    "      metrics['ari'].append(ari(labels, Z)*100)\n",
    "      try:\n",
    "        metrics['db'].append(davies_bouldin_score(features.toarray(), Z))\n",
    "      except:\n",
    "        metrics['db'].append(np.nan)\n",
    "      metrics['avg_n_clust'].append(len(np.unique(Z)))\n",
    "      \n",
    "      \n",
    "    results = {\n",
    "      'mean': {k:np.mean(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}, \n",
    "      'std': {k:np.std(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    means = results['mean']\n",
    "    std = results['std']\n",
    "    print(f'### Results on {dataset}')\n",
    "    print(f'L(X)=-{scaler}X')\n",
    "    #print(f\"{means['acc']}±{std['acc']} & {means['nmi']}±{std['nmi']} & {means['ari']}±{std['ari']}\", sep=',') \n",
    "    print(f\"acc: {means['acc']}±{std['acc']} & nmi: {means['nmi']}±{std['nmi']} & ari: {means['ari']}±{std['ari']}\", sep=',') \n",
    "    print(f\"time: {means['time']}±{std['time']}\")\n",
    "    print(f\"db-index: {means['db']}±{std['db']}\")\n",
    "    print(f\"number of clusters: {means['avg_n_clust']}\")\n",
    "    print()\n",
    "\n",
    "    if plot_block_structure:\n",
    "      import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "      fig = plt.figure(figsize=(6, 4))\n",
    "      ax = fig.add_subplot(111)\n",
    "\n",
    "      # from bcot.utils import binarize\n",
    "      # Z_p = binarize(Z_p.argmax(-1), k)\n",
    "      # W_p = binarize(W_p.argmax(-1), k)\n",
    "\n",
    "      ax.imshow((Z_p @ W_p.T)[Z.argsort()][:, W.argsort()], interpolation='nearest')\n",
    "      ax.set_aspect('auto')\n",
    "\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "      plt.savefig(f'{dataset}-block-structure.pdf')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfChZ51cKF_-"
   },
   "source": [
    "# Sinkhorn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "LYo-DlW5Em0M",
    "outputId": "1ad63b88-7e7b-40da-e6ff-2e37cb3475a0"
   },
   "outputs": [],
   "source": [
    "%cd /content/BCOT\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from bcot.utils import read_dataset\n",
    "from bcot.bcot import BCOT\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi \n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from bcot.metrics import clustering_accuracy\n",
    "import numpy as np\n",
    "from time import time \n",
    "\n",
    "n_runs = 1\n",
    "plot_block_structure = True\n",
    "\n",
    "for dataset in ['wiki']:\n",
    "  features, labels, n_classes = read_dataset(dataset, sparse=True)\n",
    "  n, d = features.shape\n",
    "  k = n_classes\n",
    "\n",
    "  for reg in [.0001, .001, .01, .1, 1, 1]:\n",
    "    for scaler in [1, n, d, k]:\n",
    "\n",
    "      metrics = {}\n",
    "      metrics['time'] = []\n",
    "      metrics['acc'] = []\n",
    "      metrics['nmi'] = []\n",
    "      metrics['ari'] = []\n",
    "      metrics['db'] = []\n",
    "      metrics['avg_n_clust'] = []\n",
    "      \n",
    "\n",
    "      for _ in range(n_runs):\n",
    "        t0 = time()\n",
    "        M = -features * scaler\n",
    "        \n",
    "        Z_p, W_p = BCOT(M, n_classes, algorithm='sinkhorn', reg=reg, n_iter=100)\n",
    "\n",
    "        Z = Z_p.argmax(-1)\n",
    "        W = W_p.argmax(-1)\n",
    "\n",
    "        metrics['time'].append(time()-t0)\n",
    "        metrics['acc'].append(clustering_accuracy(labels, Z)*100)\n",
    "        metrics['nmi'].append(nmi(labels, Z)*100)\n",
    "        metrics['ari'].append(ari(labels, Z)*100)\n",
    "        try:\n",
    "          metrics['db'].append(davies_bouldin_score(features.toarray(), Z))\n",
    "        except:\n",
    "          metrics['db'].append(np.nan)\n",
    "        metrics['avg_n_clust'].append(len(np.unique(Z)))\n",
    "        \n",
    "        \n",
    "      results = {\n",
    "        'mean': {k:np.mean(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}, \n",
    "        'std': {k:np.std(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}\n",
    "      }\n",
    "      \n",
    "      \n",
    "      means = results['mean']\n",
    "      std = results['std']\n",
    "      print(f'### Results on {dataset}')\n",
    "      print(f'L(X)=-{scaler}X, λ={reg}')\n",
    "      print(f\"{means['acc']}±{std['acc']} & {means['nmi']}±{std['nmi']} & {means['ari']}±{std['ari']}\", sep=',') \n",
    "      print(f\"time: {means['time']}±{std['time']}\")\n",
    "      print(f\"db-index: {means['db']}±{std['db']}\")\n",
    "      print(f\"number of clusters: {means['avg_n_clust']}\")\n",
    "      print()\n",
    "\n",
    "      if plot_block_structure:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        # from bcot.utils import binarize\n",
    "        # Z_p = binarize(Z_p.argmax(-1), k)\n",
    "        # W_p = binarize(W_p.argmax(-1), k)\n",
    "\n",
    "        ax.imshow((Z_p @ W_p.T)[Z.argsort()][:, W.argsort()], interpolation='nearest')\n",
    "        ax.set_aspect('auto')\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f'{dataset}-block-structure.pdf')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "document_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
