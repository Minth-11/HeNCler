{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATawChj-KEB5"
   },
   "source": [
    " # EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /volume1/scratch/zopdebee/anaconda3/envs/BCOT/lib/python3.12/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IhXzrKmR_oul",
    "outputId": "5795ab00-0398-4aab-f725-f3af036eec7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/BCOT'\n",
      "/volume1/scratch/zopdebee/GitHub/HeNCler/BCOT-main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 20/20 [01:16<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-1X\n",
      "acc: 55.2±2.5 & nmi: 16.5±1.3 & ari: 13.6±1.5\n",
      "time: 3.72±1.05\n",
      "db-index: 6.9±0.3\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 20/20 [01:20<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-19717X\n",
      "acc: 50.6±4.2 & nmi: 14.8±1.8 & ari: 11.5±2.0\n",
      "time: 3.93±1.27\n",
      "db-index: 7.1±0.3\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 20/20 [01:28<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-500X\n",
      "acc: 53.0±4.1 & nmi: 15.0±2.5 & ari: 12.2±2.4\n",
      "time: 4.34±0.81\n",
      "db-index: 7.1±0.5\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 20/20 [01:33<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Results on pubmed\n",
      "L(X)=-3X\n",
      "acc: 53.3±3.3 & nmi: 15.5±1.9 & ari: 12.4±2.1\n",
      "time: 4.59±1.32\n",
      "db-index: 6.9±0.2\n",
      "number of clusters: 3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████▍             | 14/20 [00:09<00:04,  1.49it/s]"
     ]
    }
   ],
   "source": [
    "%cd /content/BCOT\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import sys\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from bcot.utils import read_dataset\n",
    "from bcot.bcot import BCOT\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi \n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from bcot.metrics import clustering_accuracy\n",
    "import numpy as np\n",
    "from time import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "n_runs = 20\n",
    "plot_block_structure = False\n",
    "\n",
    "#for dataset in ['wiki', 'pubmed', 'ng20']:\n",
    "#for dataset in ['wiki', 'pubmed', 'acm', 'dblp', 'ohscal', 'ng20']:\n",
    "for dataset in ['pubmed','acm']:\n",
    "  features, labels, n_classes = read_dataset(dataset, sparse=True)\n",
    "  n, d = features.shape\n",
    "  k = n_classes\n",
    "\n",
    "  for scaler in [1, n, d, k]:    \n",
    "\n",
    "    metrics = {}\n",
    "    metrics['time'] = []\n",
    "    metrics['acc'] = []\n",
    "    metrics['nmi'] = []\n",
    "    metrics['ari'] = []\n",
    "    metrics['db'] = []\n",
    "    metrics['avg_n_clust'] = []\n",
    "    \n",
    "\n",
    "    for _ in tqdm(range(n_runs)):\n",
    "      t0 = time()\n",
    "      M = -features * scaler\n",
    "      \n",
    "      Z_p, W_p = BCOT(M, n_classes, algorithm='emd', reg=1, n_iter=100)\n",
    "\n",
    "      Z = Z_p.argmax(-1)\n",
    "      W = W_p.argmax(-1)\n",
    "\n",
    "      metrics['time'].append(time()-t0)\n",
    "      metrics['acc'].append(clustering_accuracy(labels, Z)*100)\n",
    "      metrics['nmi'].append(nmi(labels, Z)*100)\n",
    "      metrics['ari'].append(ari(labels, Z)*100)\n",
    "      try:\n",
    "        metrics['db'].append(davies_bouldin_score(features.toarray(), Z))\n",
    "      except:\n",
    "        metrics['db'].append(np.nan)\n",
    "      metrics['avg_n_clust'].append(len(np.unique(Z)))\n",
    "      \n",
    "      \n",
    "    results = {\n",
    "      'mean': {k:np.mean(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}, \n",
    "      'std': {k:np.std(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    means = results['mean']\n",
    "    std = results['std']\n",
    "    print(f'### Results on {dataset}')\n",
    "    print(f'L(X)=-{scaler}X')\n",
    "    #print(f\"{means['acc']}±{std['acc']} & {means['nmi']}±{std['nmi']} & {means['ari']}±{std['ari']}\", sep=',') \n",
    "    print(f\"acc: {means['acc']}±{std['acc']} & nmi: {means['nmi']}±{std['nmi']} & ari: {means['ari']}±{std['ari']}\", sep=',') \n",
    "    print(f\"time: {means['time']}±{std['time']}\")\n",
    "    print(f\"db-index: {means['db']}±{std['db']}\")\n",
    "    print(f\"number of clusters: {means['avg_n_clust']}\")\n",
    "    print()\n",
    "\n",
    "    if plot_block_structure:\n",
    "      import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "      fig = plt.figure(figsize=(6, 4))\n",
    "      ax = fig.add_subplot(111)\n",
    "\n",
    "      # from bcot.utils import binarize\n",
    "      # Z_p = binarize(Z_p.argmax(-1), k)\n",
    "      # W_p = binarize(W_p.argmax(-1), k)\n",
    "\n",
    "      ax.imshow((Z_p @ W_p.T)[Z.argsort()][:, W.argsort()], interpolation='nearest')\n",
    "      ax.set_aspect('auto')\n",
    "\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "      plt.savefig(f'{dataset}-block-structure.pdf')\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfChZ51cKF_-"
   },
   "source": [
    "# Sinkhorn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "LYo-DlW5Em0M",
    "outputId": "1ad63b88-7e7b-40da-e6ff-2e37cb3475a0"
   },
   "outputs": [],
   "source": [
    "%cd /content/BCOT\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from bcot.utils import read_dataset\n",
    "from bcot.bcot import BCOT\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi \n",
    "from sklearn.metrics import adjusted_rand_score as ari\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from bcot.metrics import clustering_accuracy\n",
    "import numpy as np\n",
    "from time import time \n",
    "\n",
    "n_runs = 1\n",
    "plot_block_structure = True\n",
    "\n",
    "for dataset in ['wiki']:\n",
    "  features, labels, n_classes = read_dataset(dataset, sparse=True)\n",
    "  n, d = features.shape\n",
    "  k = n_classes\n",
    "\n",
    "  for reg in [.0001, .001, .01, .1, 1, 1]:\n",
    "    for scaler in [1, n, d, k]:\n",
    "\n",
    "      metrics = {}\n",
    "      metrics['time'] = []\n",
    "      metrics['acc'] = []\n",
    "      metrics['nmi'] = []\n",
    "      metrics['ari'] = []\n",
    "      metrics['db'] = []\n",
    "      metrics['avg_n_clust'] = []\n",
    "      \n",
    "\n",
    "      for _ in range(n_runs):\n",
    "        t0 = time()\n",
    "        M = -features * scaler\n",
    "        \n",
    "        Z_p, W_p = BCOT(M, n_classes, algorithm='sinkhorn', reg=reg, n_iter=100)\n",
    "\n",
    "        Z = Z_p.argmax(-1)\n",
    "        W = W_p.argmax(-1)\n",
    "\n",
    "        metrics['time'].append(time()-t0)\n",
    "        metrics['acc'].append(clustering_accuracy(labels, Z)*100)\n",
    "        metrics['nmi'].append(nmi(labels, Z)*100)\n",
    "        metrics['ari'].append(ari(labels, Z)*100)\n",
    "        try:\n",
    "          metrics['db'].append(davies_bouldin_score(features.toarray(), Z))\n",
    "        except:\n",
    "          metrics['db'].append(np.nan)\n",
    "        metrics['avg_n_clust'].append(len(np.unique(Z)))\n",
    "        \n",
    "        \n",
    "      results = {\n",
    "        'mean': {k:np.mean(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}, \n",
    "        'std': {k:np.std(v).round(1 if k != 'time' else 2) for k,v in metrics.items()}\n",
    "      }\n",
    "      \n",
    "      \n",
    "      means = results['mean']\n",
    "      std = results['std']\n",
    "      print(f'### Results on {dataset}')\n",
    "      print(f'L(X)=-{scaler}X, λ={reg}')\n",
    "      print(f\"{means['acc']}±{std['acc']} & {means['nmi']}±{std['nmi']} & {means['ari']}±{std['ari']}\", sep=',') \n",
    "      print(f\"time: {means['time']}±{std['time']}\")\n",
    "      print(f\"db-index: {means['db']}±{std['db']}\")\n",
    "      print(f\"number of clusters: {means['avg_n_clust']}\")\n",
    "      print()\n",
    "\n",
    "      if plot_block_structure:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize=(6, 4))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        # from bcot.utils import binarize\n",
    "        # Z_p = binarize(Z_p.argmax(-1), k)\n",
    "        # W_p = binarize(W_p.argmax(-1), k)\n",
    "\n",
    "        ax.imshow((Z_p @ W_p.T)[Z.argsort()][:, W.argsort()], interpolation='nearest')\n",
    "        ax.set_aspect('auto')\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f'{dataset}-block-structure.pdf')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "document_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
